{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1.Lectura de los Datos\n"
      ],
      "metadata": {
        "id": "50vx0LJ2qUOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x8j7BEMQPWsL",
        "outputId": "9216fda6-5345-45df-db74-6fe896cb7f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "r28V7WDMot80",
        "outputId": "902325a4-f284-4612-9fe8-6226b8f11ea4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price    343221.272051\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>343221.272051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#1.lectura del dataset de entrenamiento\n",
        "df_Rstate_train=pd.read_csv(\"X_train.csv\")\n",
        "df_Rstate_train\n",
        "\n",
        "#2.lectura del dataset de Test\n",
        "df_Rstate_test=pd.read_csv(\"X_test.csv\")\n",
        "df_Rstate_test\n",
        "\n",
        "#lectura del dataset \"Y\" de entrenamiento\n",
        "df_y_train=pd.read_csv(\"y_train.csv\")\n",
        "df_y_train.drop(\"id_annonce\", axis=1, inplace=True)\n",
        "df_y_train\n",
        "\n",
        "#lectura del dataset \"Y\" de test\n",
        "df_y_test=pd.read_csv(\"y_random.csv\")\n",
        "df_y_test.drop(\"id_annonce\", axis=1, inplace=True)\n",
        "df_y_test\n",
        "\n",
        "df_y_train.mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Informacion del dataset de entrenamiento\n",
        "\n",
        "df_Rstate_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtjhkK_4rIDj",
        "outputId": "3e57008c-ec50-4301-e712-5c6cf2c827e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 37368 entries, 0 to 37367\n",
            "Data columns (total 27 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   id_annonce                   37368 non-null  int64  \n",
            " 1   property_type                37368 non-null  object \n",
            " 2   approximate_latitude         37368 non-null  float64\n",
            " 3   approximate_longitude        37368 non-null  float64\n",
            " 4   city                         37368 non-null  object \n",
            " 5   postal_code                  37368 non-null  int64  \n",
            " 6   size                         36856 non-null  float64\n",
            " 7   floor                        9743 non-null   float64\n",
            " 8   land_size                    15581 non-null  float64\n",
            " 9   energy_performance_value     19068 non-null  float64\n",
            " 10  energy_performance_category  19068 non-null  object \n",
            " 11  ghg_value                    18530 non-null  float64\n",
            " 12  ghg_category                 18530 non-null  object \n",
            " 13  exposition                   9094 non-null   object \n",
            " 14  nb_rooms                     35802 non-null  float64\n",
            " 15  nb_bedrooms                  34635 non-null  float64\n",
            " 16  nb_bathrooms                 24095 non-null  float64\n",
            " 17  nb_parking_places            37368 non-null  float64\n",
            " 18  nb_boxes                     37368 non-null  float64\n",
            " 19  nb_photos                    37368 non-null  float64\n",
            " 20  has_a_balcony                37368 non-null  float64\n",
            " 21  nb_terraces                  37368 non-null  float64\n",
            " 22  has_a_cellar                 37368 non-null  float64\n",
            " 23  has_a_garage                 37368 non-null  float64\n",
            " 24  has_air_conditioning         37368 non-null  float64\n",
            " 25  last_floor                   37368 non-null  float64\n",
            " 26  upper_floors                 37368 non-null  float64\n",
            "dtypes: float64(20), int64(2), object(5)\n",
            "memory usage: 7.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.informacion del dataset de test\n",
        "\n",
        "df_Rstate_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKw4J_6DvQfc",
        "outputId": "25b11eff-1aef-4fed-f468-ac51108eee8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9339 entries, 0 to 9338\n",
            "Data columns (total 27 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   id_annonce                   9339 non-null   int64  \n",
            " 1   property_type                9339 non-null   object \n",
            " 2   approximate_latitude         9339 non-null   float64\n",
            " 3   approximate_longitude        9339 non-null   float64\n",
            " 4   city                         9339 non-null   object \n",
            " 5   postal_code                  9339 non-null   int64  \n",
            " 6   size                         9203 non-null   float64\n",
            " 7   floor                        2485 non-null   float64\n",
            " 8   land_size                    3852 non-null   float64\n",
            " 9   energy_performance_value     4828 non-null   float64\n",
            " 10  energy_performance_category  4828 non-null   object \n",
            " 11  ghg_value                    4679 non-null   float64\n",
            " 12  ghg_category                 4679 non-null   object \n",
            " 13  exposition                   2325 non-null   object \n",
            " 14  nb_rooms                     8985 non-null   float64\n",
            " 15  nb_bedrooms                  8705 non-null   float64\n",
            " 16  nb_bathrooms                 6035 non-null   float64\n",
            " 17  nb_parking_places            9339 non-null   float64\n",
            " 18  nb_boxes                     9339 non-null   float64\n",
            " 19  nb_photos                    9339 non-null   float64\n",
            " 20  has_a_balcony                9339 non-null   float64\n",
            " 21  nb_terraces                  9339 non-null   float64\n",
            " 22  has_a_cellar                 9339 non-null   float64\n",
            " 23  has_a_garage                 9339 non-null   float64\n",
            " 24  has_air_conditioning         9339 non-null   float64\n",
            " 25  last_floor                   9339 non-null   float64\n",
            " 26  upper_floors                 9339 non-null   float64\n",
            "dtypes: float64(20), int64(2), object(5)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Separar las variables numericas del dataset de Entrenamiento y de Test\n",
        "\n",
        "df_Rstate_train_num = df_Rstate_train.loc[:, ['approximate_latitude',\n",
        "                                              'approximate_longitude',\n",
        "                                              'size','floor','land_size',\n",
        "                                              'energy_performance_value',\n",
        "                                              'ghg_value','nb_rooms','nb_bedrooms','nb_bathrooms',\n",
        "                                              'nb_parking_places','nb_boxes',]].copy()\n",
        "\n",
        "df_Rstate_test_num = df_Rstate_test.loc[:, ['approximate_latitude',\n",
        "                                              'approximate_longitude',\n",
        "                                              'size','floor','land_size',\n",
        "                                              'energy_performance_value',\n",
        "                                              'ghg_value','nb_rooms','nb_bedrooms','nb_bathrooms',\n",
        "                                              'nb_parking_places','nb_boxes',]].copy()"
      ],
      "metadata": {
        "id": "xkEy9eBsu_yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Rstate_train_num.shape, df_Rstate_test_num.shape, df_y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UEr7qnV1mbp",
        "outputId": "b66633ae-5f02-486b-c91a-c68263f28f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37368, 12), (9339, 12), (37368, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imputamos los valores faltantes con la media para cada columna numerica\n",
        "\n",
        "df_Rstate_train_num = df_Rstate_train_num.fillna(df_Rstate_train_num.median(numeric_only=True))\n",
        "df_Rstate_test_num = df_Rstate_test_num.fillna(df_Rstate_test_num.median(numeric_only=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "Vza2hsv6R-co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizacion de los Datos tanto X como Y\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Crear el objeto escalador\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustar SOLO con el entrenamiento y transformar\n",
        "X_train_scaled = scaler.fit_transform(df_Rstate_train_num)\n",
        "\n",
        "# Transformar los datos de prueba usando los parámetros calculados en train\n",
        "X_test_scaled = scaler.transform(df_Rstate_test_num )\n",
        "\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(df_y_train.values.reshape(-1,1))\n",
        "\n",
        "y_test_scaled = y_scaler.transform(df_y_test.values.reshape(-1,1))"
      ],
      "metadata": {
        "id": "PeHDFlM9ONeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=df_Rstate_train_num.columns)\n",
        "y_train_scaled = pd.DataFrame(y_train_scaled, columns=df_y_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=df_Rstate_test_num.columns)\n",
        "y_test_scaled = pd.DataFrame(y_test_scaled, columns=df_y_test.columns)\n",
        "\n",
        "X_train_scaled.shape, y_train_scaled.shape, X_test_scaled.shape, y_test_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZB32Qbl3QolO",
        "outputId": "1be15602-3091-41e1-d23d-45b721ee4cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37368, 12), (37368, 1), (9339, 12), (9339, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Encontrar las Variables mas Correlacionadas\n"
      ],
      "metadata": {
        "id": "uefKnwZ8kfD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Unimos los datasets X_train_scaled y y_train_sacled  temporalmente para ver las variables mas correlacionadas\n",
        "df_correlacion = X_train_scaled.copy()\n",
        "df_correlacion[\"Price\"] = y_train_scaled\n",
        "\n",
        "# Calculamos correlación\n",
        "corr = df_correlacion.corr(numeric_only=True)[\"Price\"].sort_values(ascending=False)\n",
        "\n",
        "print(corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rMtI7YRyqo-8",
        "outputId": "33e30395-c239-4d39-cad2-00f3d7aac247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price                       1.000000\n",
            "nb_rooms                    0.303781\n",
            "nb_bedrooms                 0.288266\n",
            "nb_bathrooms                0.172911\n",
            "approximate_longitude       0.095404\n",
            "floor                       0.076731\n",
            "nb_parking_places           0.064793\n",
            "land_size                   0.037572\n",
            "approximate_latitude        0.034801\n",
            "size                        0.034754\n",
            "nb_boxes                    0.030988\n",
            "ghg_value                  -0.010407\n",
            "energy_performance_value   -0.021864\n",
            "Name: Price, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Creo el dataset solo con las 3 variables mas correlacionadas y seran los dataframes que se usaran como dataset de la red neuronal\n",
        "\n",
        "X_train=X_train_scaled[[\"nb_rooms\",\"nb_bedrooms\",\"nb_bathrooms\"]]\n",
        "X_test=X_test_scaled[[\"nb_rooms\",\"nb_bedrooms\",\"nb_bathrooms\"]]\n",
        "y_train=y_train_scaled\n",
        "y_test=y_test_scaled\n",
        "\n",
        "#Del dataset de entrenamiento extraigo una parte del dataset para validacion\n",
        "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "print('Tamaño del dataset de Entrenamiento ', X_train.shape, y_train.shape)\n",
        "print('Tamaño del dataset de Validacion ', X_val.shape,y_val.shape)\n",
        "print('Tamaño del dataset de Test ', X_test.shape,y_test.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kznU0mOwBGSi",
        "outputId": "c78f503c-150c-4221-a372-ab2124d41bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del dataset de Entrenamiento  (29894, 3) (29894, 1)\n",
            "Tamaño del dataset de Validacion  (7474, 3) (7474, 1)\n",
            "Tamaño del dataset de Test  (9339, 3) (9339, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Definicion de la red Neuronal con regresion lineal\n"
      ],
      "metadata": {
        "id": "eV8xTZb_vCI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#defino una funcion para crear las redes neuronales\n",
        "\n",
        "\n",
        "def build_model_regresion(lr_var,neuronas,drop_out,input_data):\n",
        "    model_Rstate = tf.keras.models.Sequential([\n",
        "                    #1.primera capa de entrada con dropout de 20%\n",
        "                    keras.layers.Dense(neuronas, activation='relu', input_shape=(input_data,)),\n",
        "                    keras.layers.Dropout(drop_out),\n",
        "\n",
        "                    #2.segunda capa con dropout de 20%\n",
        "                    keras.layers.Dense(neuronas, activation='relu'),\n",
        "                    #3.tercera capa de salida\n",
        "                    keras.layers.Dense(1)])\n",
        "\n",
        "    model_Rstate.compile(\n",
        "          optimizer=Adam(learning_rate=lr_var),\n",
        "          loss='mse',         # error cuadrático medio\n",
        "          metrics=['mae'] )   # error absoluto medio\n",
        "\n",
        "    return model_Rstate"
      ],
      "metadata": {
        "id": "E5nyxehUsmT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo la red neuronal con los parametros entrenables\n",
        "#los hiperparametros en este caso serian learning_rate,numero de neuronas de cada capa , porcentaje de dropout de la red , entrada de datos\n",
        "\n",
        "RN_Regresion=build_model_regresion(0.001,16,0.20,3)\n",
        "RN_Regresion.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "lxX0lAJv5iGG",
        "outputId": "187d0e65-8c17-4ecc-85b2-8aa04df6a58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353\u001b[0m (1.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353</span> (1.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m353\u001b[0m (1.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353</span> (1.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejecuto la red Neuronal y guardo su historial\n",
        "\n",
        "History=RN_Regresion.fit(X_train,\n",
        "                         y_train,\n",
        "                         epochs=100,\n",
        "                         batch_size=512,\n",
        "                         validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Msjfqxs4DTFf",
        "outputId": "54d8f861-fb67-40dc-b359-f0e23ca40549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.0261 - mae: 0.6300 - val_loss: 0.8948 - val_mae: 0.6266\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9402 - mae: 0.6350 - val_loss: 0.8874 - val_mae: 0.6250\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9266 - mae: 0.6257 - val_loss: 0.8867 - val_mae: 0.6273\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9049 - mae: 0.6240 - val_loss: 0.8824 - val_mae: 0.6231\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9020 - mae: 0.6246 - val_loss: 0.8751 - val_mae: 0.6185\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8689 - mae: 0.6124 - val_loss: 0.8765 - val_mae: 0.6248\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8707 - mae: 0.6166 - val_loss: 0.8744 - val_mae: 0.6230\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8791 - mae: 0.6205 - val_loss: 0.8738 - val_mae: 0.6213\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8899 - mae: 0.6221 - val_loss: 0.8745 - val_mae: 0.6247\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8931 - mae: 0.6233 - val_loss: 0.8724 - val_mae: 0.6205\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8846 - mae: 0.6149 - val_loss: 0.8714 - val_mae: 0.6210\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9072 - mae: 0.6268 - val_loss: 0.8714 - val_mae: 0.6193\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9234 - mae: 0.6302 - val_loss: 0.8707 - val_mae: 0.6204\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8928 - mae: 0.6179 - val_loss: 0.8737 - val_mae: 0.6254\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8822 - mae: 0.6211 - val_loss: 0.8703 - val_mae: 0.6207\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8957 - mae: 0.6211 - val_loss: 0.8702 - val_mae: 0.6192\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8753 - mae: 0.6135 - val_loss: 0.8711 - val_mae: 0.6242\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8688 - mae: 0.6126 - val_loss: 0.8703 - val_mae: 0.6215\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8986 - mae: 0.6234 - val_loss: 0.8688 - val_mae: 0.6175\n",
            "Epoch 20/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8903 - mae: 0.6186 - val_loss: 0.8699 - val_mae: 0.6196\n",
            "Epoch 21/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8525 - mae: 0.6099 - val_loss: 0.8704 - val_mae: 0.6237\n",
            "Epoch 22/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8660 - mae: 0.6172 - val_loss: 0.8702 - val_mae: 0.6247\n",
            "Epoch 23/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8599 - mae: 0.6135 - val_loss: 0.8710 - val_mae: 0.6277\n",
            "Epoch 24/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8933 - mae: 0.6189 - val_loss: 0.8689 - val_mae: 0.6206\n",
            "Epoch 25/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8817 - mae: 0.6183 - val_loss: 0.8683 - val_mae: 0.6196\n",
            "Epoch 26/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8679 - mae: 0.6111 - val_loss: 0.8699 - val_mae: 0.6200\n",
            "Epoch 27/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8760 - mae: 0.6133 - val_loss: 0.8722 - val_mae: 0.6290\n",
            "Epoch 28/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8913 - mae: 0.6233 - val_loss: 0.8709 - val_mae: 0.6226\n",
            "Epoch 29/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8901 - mae: 0.6201 - val_loss: 0.8716 - val_mae: 0.6258\n",
            "Epoch 30/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8889 - mae: 0.6212 - val_loss: 0.8704 - val_mae: 0.6215\n",
            "Epoch 31/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8694 - mae: 0.6142 - val_loss: 0.8686 - val_mae: 0.6188\n",
            "Epoch 32/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8718 - mae: 0.6166 - val_loss: 0.8693 - val_mae: 0.6235\n",
            "Epoch 33/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8656 - mae: 0.6122 - val_loss: 0.8701 - val_mae: 0.6252\n",
            "Epoch 34/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9010 - mae: 0.6213 - val_loss: 0.8686 - val_mae: 0.6161\n",
            "Epoch 35/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8650 - mae: 0.6091 - val_loss: 0.8706 - val_mae: 0.6229\n",
            "Epoch 36/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8636 - mae: 0.6128 - val_loss: 0.8708 - val_mae: 0.6257\n",
            "Epoch 37/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8738 - mae: 0.6117 - val_loss: 0.8707 - val_mae: 0.6223\n",
            "Epoch 38/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8821 - mae: 0.6143 - val_loss: 0.8697 - val_mae: 0.6260\n",
            "Epoch 39/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8600 - mae: 0.6128 - val_loss: 0.8704 - val_mae: 0.6259\n",
            "Epoch 40/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8609 - mae: 0.6100 - val_loss: 0.8690 - val_mae: 0.6220\n",
            "Epoch 41/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8758 - mae: 0.6158 - val_loss: 0.8690 - val_mae: 0.6232\n",
            "Epoch 42/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8881 - mae: 0.6184 - val_loss: 0.8680 - val_mae: 0.6219\n",
            "Epoch 43/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8931 - mae: 0.6192 - val_loss: 0.8672 - val_mae: 0.6171\n",
            "Epoch 44/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8753 - mae: 0.6108 - val_loss: 0.8698 - val_mae: 0.6247\n",
            "Epoch 45/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8772 - mae: 0.6155 - val_loss: 0.8687 - val_mae: 0.6217\n",
            "Epoch 46/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8802 - mae: 0.6172 - val_loss: 0.8691 - val_mae: 0.6240\n",
            "Epoch 47/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8893 - mae: 0.6178 - val_loss: 0.8687 - val_mae: 0.6212\n",
            "Epoch 48/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8452 - mae: 0.6054 - val_loss: 0.8712 - val_mae: 0.6329\n",
            "Epoch 49/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8928 - mae: 0.6280 - val_loss: 0.8695 - val_mae: 0.6209\n",
            "Epoch 50/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8774 - mae: 0.6152 - val_loss: 0.8694 - val_mae: 0.6265\n",
            "Epoch 51/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8721 - mae: 0.6111 - val_loss: 0.8694 - val_mae: 0.6273\n",
            "Epoch 52/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8896 - mae: 0.6233 - val_loss: 0.8695 - val_mae: 0.6271\n",
            "Epoch 53/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8841 - mae: 0.6184 - val_loss: 0.8681 - val_mae: 0.6210\n",
            "Epoch 54/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8567 - mae: 0.6092 - val_loss: 0.8690 - val_mae: 0.6244\n",
            "Epoch 55/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9049 - mae: 0.6227 - val_loss: 0.8677 - val_mae: 0.6195\n",
            "Epoch 56/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8731 - mae: 0.6139 - val_loss: 0.8689 - val_mae: 0.6244\n",
            "Epoch 57/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8636 - mae: 0.6125 - val_loss: 0.8701 - val_mae: 0.6283\n",
            "Epoch 58/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8683 - mae: 0.6137 - val_loss: 0.8673 - val_mae: 0.6217\n",
            "Epoch 59/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8794 - mae: 0.6195 - val_loss: 0.8685 - val_mae: 0.6203\n",
            "Epoch 60/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8644 - mae: 0.6119 - val_loss: 0.8685 - val_mae: 0.6255\n",
            "Epoch 61/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8450 - mae: 0.6075 - val_loss: 0.8683 - val_mae: 0.6239\n",
            "Epoch 62/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8936 - mae: 0.6206 - val_loss: 0.8684 - val_mae: 0.6244\n",
            "Epoch 63/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8574 - mae: 0.6097 - val_loss: 0.8683 - val_mae: 0.6276\n",
            "Epoch 64/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9140 - mae: 0.6255 - val_loss: 0.8671 - val_mae: 0.6227\n",
            "Epoch 65/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9037 - mae: 0.6248 - val_loss: 0.8684 - val_mae: 0.6238\n",
            "Epoch 66/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8663 - mae: 0.6116 - val_loss: 0.8694 - val_mae: 0.6288\n",
            "Epoch 67/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8617 - mae: 0.6136 - val_loss: 0.8672 - val_mae: 0.6228\n",
            "Epoch 68/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8695 - mae: 0.6114 - val_loss: 0.8691 - val_mae: 0.6278\n",
            "Epoch 69/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8875 - mae: 0.6205 - val_loss: 0.8683 - val_mae: 0.6229\n",
            "Epoch 70/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8889 - mae: 0.6169 - val_loss: 0.8671 - val_mae: 0.6196\n",
            "Epoch 71/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8651 - mae: 0.6078 - val_loss: 0.8673 - val_mae: 0.6205\n",
            "Epoch 72/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8823 - mae: 0.6179 - val_loss: 0.8677 - val_mae: 0.6235\n",
            "Epoch 73/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8920 - mae: 0.6182 - val_loss: 0.8672 - val_mae: 0.6226\n",
            "Epoch 74/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9017 - mae: 0.6229 - val_loss: 0.8679 - val_mae: 0.6194\n",
            "Epoch 75/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8724 - mae: 0.6132 - val_loss: 0.8666 - val_mae: 0.6231\n",
            "Epoch 76/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8674 - mae: 0.6120 - val_loss: 0.8663 - val_mae: 0.6227\n",
            "Epoch 77/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8689 - mae: 0.6136 - val_loss: 0.8668 - val_mae: 0.6207\n",
            "Epoch 78/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8867 - mae: 0.6149 - val_loss: 0.8690 - val_mae: 0.6232\n",
            "Epoch 79/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8561 - mae: 0.6073 - val_loss: 0.8681 - val_mae: 0.6261\n",
            "Epoch 80/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8845 - mae: 0.6220 - val_loss: 0.8676 - val_mae: 0.6246\n",
            "Epoch 81/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8880 - mae: 0.6145 - val_loss: 0.8673 - val_mae: 0.6240\n",
            "Epoch 82/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8642 - mae: 0.6153 - val_loss: 0.8670 - val_mae: 0.6233\n",
            "Epoch 83/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8625 - mae: 0.6105 - val_loss: 0.8683 - val_mae: 0.6289\n",
            "Epoch 84/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8697 - mae: 0.6181 - val_loss: 0.8676 - val_mae: 0.6244\n",
            "Epoch 85/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8586 - mae: 0.6072 - val_loss: 0.8671 - val_mae: 0.6254\n",
            "Epoch 86/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8929 - mae: 0.6191 - val_loss: 0.8678 - val_mae: 0.6240\n",
            "Epoch 87/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8868 - mae: 0.6189 - val_loss: 0.8663 - val_mae: 0.6212\n",
            "Epoch 88/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8714 - mae: 0.6157 - val_loss: 0.8668 - val_mae: 0.6244\n",
            "Epoch 89/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8772 - mae: 0.6172 - val_loss: 0.8680 - val_mae: 0.6277\n",
            "Epoch 90/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8617 - mae: 0.6121 - val_loss: 0.8678 - val_mae: 0.6284\n",
            "Epoch 91/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8780 - mae: 0.6145 - val_loss: 0.8676 - val_mae: 0.6244\n",
            "Epoch 92/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8849 - mae: 0.6173 - val_loss: 0.8666 - val_mae: 0.6207\n",
            "Epoch 93/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8892 - mae: 0.6205 - val_loss: 0.8667 - val_mae: 0.6237\n",
            "Epoch 94/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8736 - mae: 0.6158 - val_loss: 0.8702 - val_mae: 0.6304\n",
            "Epoch 95/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8713 - mae: 0.6147 - val_loss: 0.8682 - val_mae: 0.6266\n",
            "Epoch 96/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8916 - mae: 0.6194 - val_loss: 0.8667 - val_mae: 0.6204\n",
            "Epoch 97/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8854 - mae: 0.6137 - val_loss: 0.8682 - val_mae: 0.6285\n",
            "Epoch 98/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8773 - mae: 0.6137 - val_loss: 0.8699 - val_mae: 0.6294\n",
            "Epoch 99/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8771 - mae: 0.6167 - val_loss: 0.8661 - val_mae: 0.6229\n",
            "Epoch 100/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8711 - mae: 0.6130 - val_loss: 0.8681 - val_mae: 0.6288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "History.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeH16PYGbNB8",
        "outputId": "6bbddf5d-1f64-4560-e331-5b4ca7c6342d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.9284992814064026,\n",
              "  0.8872761130332947,\n",
              "  0.8875582218170166,\n",
              "  0.8849360942840576,\n",
              "  0.8824700117111206,\n",
              "  0.8817809820175171,\n",
              "  0.8840203285217285,\n",
              "  0.8822095394134521,\n",
              "  0.8835544586181641,\n",
              "  0.8786989450454712,\n",
              "  0.8805490732192993,\n",
              "  0.8803931474685669,\n",
              "  0.8773631453514099,\n",
              "  0.8783050179481506,\n",
              "  0.8789458870887756,\n",
              "  0.878038227558136,\n",
              "  0.877951979637146,\n",
              "  0.8778710961341858,\n",
              "  0.877805769443512,\n",
              "  0.8774493932723999,\n",
              "  0.8772023916244507,\n",
              "  0.8775672912597656,\n",
              "  0.8767704367637634,\n",
              "  0.8775336742401123,\n",
              "  0.8771762847900391,\n",
              "  0.8758292198181152,\n",
              "  0.8760274648666382,\n",
              "  0.8768693804740906,\n",
              "  0.877671480178833,\n",
              "  0.8757364749908447,\n",
              "  0.8767946362495422,\n",
              "  0.8761048913002014,\n",
              "  0.877487301826477,\n",
              "  0.877424955368042,\n",
              "  0.87491375207901,\n",
              "  0.8757229447364807,\n",
              "  0.877069890499115,\n",
              "  0.8762994408607483,\n",
              "  0.8762574791908264,\n",
              "  0.8768496513366699,\n",
              "  0.8758051991462708,\n",
              "  0.8746597766876221,\n",
              "  0.8755583763122559,\n",
              "  0.8744075894355774,\n",
              "  0.8758797645568848,\n",
              "  0.8755797147750854,\n",
              "  0.8754897713661194,\n",
              "  0.874859631061554,\n",
              "  0.8745377063751221,\n",
              "  0.8754643201828003,\n",
              "  0.8748477101325989,\n",
              "  0.8764479160308838,\n",
              "  0.8750882148742676,\n",
              "  0.8748298287391663,\n",
              "  0.874487578868866,\n",
              "  0.873721182346344,\n",
              "  0.8754090666770935,\n",
              "  0.8746856451034546,\n",
              "  0.8754606246948242,\n",
              "  0.8748838901519775,\n",
              "  0.8747261166572571,\n",
              "  0.8770722150802612,\n",
              "  0.8739364743232727,\n",
              "  0.8753165006637573,\n",
              "  0.8738459944725037,\n",
              "  0.8753334283828735,\n",
              "  0.8739922642707825,\n",
              "  0.8749165534973145,\n",
              "  0.8734792470932007,\n",
              "  0.8737972378730774,\n",
              "  0.8738945126533508,\n",
              "  0.8745616674423218,\n",
              "  0.874023973941803,\n",
              "  0.8735558390617371,\n",
              "  0.8744373917579651,\n",
              "  0.8752147555351257,\n",
              "  0.8729908466339111,\n",
              "  0.8752859234809875,\n",
              "  0.8734718561172485,\n",
              "  0.8741864562034607,\n",
              "  0.8739965558052063,\n",
              "  0.8746256828308105,\n",
              "  0.8734897971153259,\n",
              "  0.8743644952774048,\n",
              "  0.8740357160568237,\n",
              "  0.873534083366394,\n",
              "  0.8743352293968201,\n",
              "  0.8741039037704468,\n",
              "  0.8728350400924683,\n",
              "  0.8737483620643616,\n",
              "  0.8733031153678894,\n",
              "  0.8729420900344849,\n",
              "  0.87413090467453,\n",
              "  0.8729121685028076,\n",
              "  0.8738436102867126,\n",
              "  0.8726578950881958,\n",
              "  0.8728092908859253,\n",
              "  0.8741515874862671,\n",
              "  0.8731311559677124,\n",
              "  0.8728083372116089],\n",
              " 'mae': [0.6362212300300598,\n",
              "  0.6226642727851868,\n",
              "  0.6189271807670593,\n",
              "  0.6191507577896118,\n",
              "  0.6170916557312012,\n",
              "  0.617388129234314,\n",
              "  0.6177176833152771,\n",
              "  0.6148368120193481,\n",
              "  0.6192387342453003,\n",
              "  0.6180791854858398,\n",
              "  0.6143735647201538,\n",
              "  0.6151785254478455,\n",
              "  0.6155909895896912,\n",
              "  0.6149699687957764,\n",
              "  0.6176587343215942,\n",
              "  0.6148074269294739,\n",
              "  0.6165492534637451,\n",
              "  0.6151521801948547,\n",
              "  0.6158108115196228,\n",
              "  0.6141818165779114,\n",
              "  0.6156491637229919,\n",
              "  0.6164170503616333,\n",
              "  0.6136183142662048,\n",
              "  0.6173350214958191,\n",
              "  0.6166191697120667,\n",
              "  0.6132887601852417,\n",
              "  0.6163814067840576,\n",
              "  0.6145397424697876,\n",
              "  0.6161332130432129,\n",
              "  0.6163554191589355,\n",
              "  0.6144521236419678,\n",
              "  0.6155968308448792,\n",
              "  0.6155573129653931,\n",
              "  0.6148173213005066,\n",
              "  0.615165114402771,\n",
              "  0.6151407957077026,\n",
              "  0.6151655912399292,\n",
              "  0.6153965592384338,\n",
              "  0.6143897771835327,\n",
              "  0.6153751015663147,\n",
              "  0.6149793863296509,\n",
              "  0.6139873266220093,\n",
              "  0.6149677038192749,\n",
              "  0.614848256111145,\n",
              "  0.615082323551178,\n",
              "  0.6144713759422302,\n",
              "  0.6144462823867798,\n",
              "  0.618076503276825,\n",
              "  0.6130189895629883,\n",
              "  0.6133304238319397,\n",
              "  0.6145199537277222,\n",
              "  0.6170536279678345,\n",
              "  0.6150428056716919,\n",
              "  0.6154736280441284,\n",
              "  0.6140212416648865,\n",
              "  0.6151573061943054,\n",
              "  0.6127106547355652,\n",
              "  0.6145390868186951,\n",
              "  0.6152846813201904,\n",
              "  0.6153528094291687,\n",
              "  0.6125807166099548,\n",
              "  0.615351676940918,\n",
              "  0.615230917930603,\n",
              "  0.6150511503219604,\n",
              "  0.613502562046051,\n",
              "  0.6142325401306152,\n",
              "  0.6143746376037598,\n",
              "  0.6138176321983337,\n",
              "  0.6161784529685974,\n",
              "  0.6133694648742676,\n",
              "  0.614184558391571,\n",
              "  0.6129688024520874,\n",
              "  0.6146435141563416,\n",
              "  0.6153261661529541,\n",
              "  0.6158852577209473,\n",
              "  0.6138373613357544,\n",
              "  0.6148903965950012,\n",
              "  0.6147947907447815,\n",
              "  0.6128495335578918,\n",
              "  0.6153066158294678,\n",
              "  0.6127645969390869,\n",
              "  0.6154686808586121,\n",
              "  0.6151554584503174,\n",
              "  0.6135653257369995,\n",
              "  0.6137906908988953,\n",
              "  0.6151809096336365,\n",
              "  0.6148372292518616,\n",
              "  0.6158090233802795,\n",
              "  0.613126814365387,\n",
              "  0.6134872436523438,\n",
              "  0.6128261089324951,\n",
              "  0.6142635345458984,\n",
              "  0.6143346428871155,\n",
              "  0.6142972111701965,\n",
              "  0.6143620610237122,\n",
              "  0.6136361956596375,\n",
              "  0.6142428517341614,\n",
              "  0.6131324768066406,\n",
              "  0.615775465965271,\n",
              "  0.6122899651527405],\n",
              " 'val_loss': [0.878223180770874,\n",
              "  0.8688178658485413,\n",
              "  0.8674988746643066,\n",
              "  0.8681748509407043,\n",
              "  0.864057183265686,\n",
              "  0.8638457655906677,\n",
              "  0.8632394671440125,\n",
              "  0.8657197952270508,\n",
              "  0.8680408000946045,\n",
              "  0.8628950715065002,\n",
              "  0.8632844090461731,\n",
              "  0.8636096715927124,\n",
              "  0.865074098110199,\n",
              "  0.8640989661216736,\n",
              "  0.8634291291236877,\n",
              "  0.86313396692276,\n",
              "  0.8627845644950867,\n",
              "  0.8630777597427368,\n",
              "  0.8621963858604431,\n",
              "  0.8633301854133606,\n",
              "  0.8622208833694458,\n",
              "  0.8617085218429565,\n",
              "  0.8648043870925903,\n",
              "  0.8620877861976624,\n",
              "  0.8641049265861511,\n",
              "  0.8632780909538269,\n",
              "  0.865095853805542,\n",
              "  0.8637996315956116,\n",
              "  0.8634961247444153,\n",
              "  0.8626545071601868,\n",
              "  0.8632465600967407,\n",
              "  0.8633946180343628,\n",
              "  0.8630861043930054,\n",
              "  0.8625895380973816,\n",
              "  0.8625868558883667,\n",
              "  0.8636360168457031,\n",
              "  0.8625383377075195,\n",
              "  0.8633664846420288,\n",
              "  0.863402247428894,\n",
              "  0.8643791675567627,\n",
              "  0.8635562062263489,\n",
              "  0.8628862500190735,\n",
              "  0.8626924753189087,\n",
              "  0.8642088174819946,\n",
              "  0.8634185791015625,\n",
              "  0.862737238407135,\n",
              "  0.8655989766120911,\n",
              "  0.8652955293655396,\n",
              "  0.864244818687439,\n",
              "  0.8661951422691345,\n",
              "  0.864194393157959,\n",
              "  0.8636704683303833,\n",
              "  0.8621814250946045,\n",
              "  0.8648457527160645,\n",
              "  0.8658801317214966,\n",
              "  0.8649019598960876,\n",
              "  0.8647072315216064,\n",
              "  0.8641159534454346,\n",
              "  0.8676131963729858,\n",
              "  0.8653079271316528,\n",
              "  0.8658861517906189,\n",
              "  0.867578387260437,\n",
              "  0.8650747537612915,\n",
              "  0.864102303981781,\n",
              "  0.8641471266746521,\n",
              "  0.8642381429672241,\n",
              "  0.8639674782752991,\n",
              "  0.864849865436554,\n",
              "  0.8636264204978943,\n",
              "  0.8658260107040405,\n",
              "  0.8664865493774414,\n",
              "  0.8648973703384399,\n",
              "  0.866525411605835,\n",
              "  0.8648642897605896,\n",
              "  0.8663605451583862,\n",
              "  0.866022527217865,\n",
              "  0.8646346926689148,\n",
              "  0.8638394474983215,\n",
              "  0.865536630153656,\n",
              "  0.8670276403427124,\n",
              "  0.8651872873306274,\n",
              "  0.8649865984916687,\n",
              "  0.8657925724983215,\n",
              "  0.8651984930038452,\n",
              "  0.8667072057723999,\n",
              "  0.8680309653282166,\n",
              "  0.8643770813941956,\n",
              "  0.8658218383789062,\n",
              "  0.8659430146217346,\n",
              "  0.864923357963562,\n",
              "  0.8655374050140381,\n",
              "  0.8655418157577515,\n",
              "  0.8657207489013672,\n",
              "  0.8653410077095032,\n",
              "  0.8693599104881287,\n",
              "  0.8662661910057068,\n",
              "  0.8651210069656372,\n",
              "  0.8714161515235901,\n",
              "  0.8656408190727234,\n",
              "  0.8648701310157776],\n",
              " 'val_mae': [0.619607150554657,\n",
              "  0.6075433492660522,\n",
              "  0.6148847341537476,\n",
              "  0.6122344136238098,\n",
              "  0.6147115230560303,\n",
              "  0.6089229583740234,\n",
              "  0.6039378046989441,\n",
              "  0.6246314644813538,\n",
              "  0.6192220449447632,\n",
              "  0.6044015288352966,\n",
              "  0.6066661477088928,\n",
              "  0.6115356087684631,\n",
              "  0.6161291003227234,\n",
              "  0.6202234029769897,\n",
              "  0.6118208765983582,\n",
              "  0.6164012551307678,\n",
              "  0.6145061254501343,\n",
              "  0.6180980801582336,\n",
              "  0.611404538154602,\n",
              "  0.6139236092567444,\n",
              "  0.6130579113960266,\n",
              "  0.6097240447998047,\n",
              "  0.6091158390045166,\n",
              "  0.6084591150283813,\n",
              "  0.6168254613876343,\n",
              "  0.617433488368988,\n",
              "  0.6130886077880859,\n",
              "  0.6178075075149536,\n",
              "  0.6138676404953003,\n",
              "  0.608022153377533,\n",
              "  0.6178133487701416,\n",
              "  0.6058703660964966,\n",
              "  0.606637716293335,\n",
              "  0.6131169199943542,\n",
              "  0.614027738571167,\n",
              "  0.6140567660331726,\n",
              "  0.6135987043380737,\n",
              "  0.6154598593711853,\n",
              "  0.6089990139007568,\n",
              "  0.6139844655990601,\n",
              "  0.6145638823509216,\n",
              "  0.6145347952842712,\n",
              "  0.6125224232673645,\n",
              "  0.6188870668411255,\n",
              "  0.6172330379486084,\n",
              "  0.6100517511367798,\n",
              "  0.6248015761375427,\n",
              "  0.6181510090827942,\n",
              "  0.6140598058700562,\n",
              "  0.6235445737838745,\n",
              "  0.6190993189811707,\n",
              "  0.6160260438919067,\n",
              "  0.6110337376594543,\n",
              "  0.6073808670043945,\n",
              "  0.6202970147132874,\n",
              "  0.611683189868927,\n",
              "  0.6171595454216003,\n",
              "  0.6147283911705017,\n",
              "  0.6246308088302612,\n",
              "  0.6187790632247925,\n",
              "  0.6231056451797485,\n",
              "  0.6198164820671082,\n",
              "  0.6209855675697327,\n",
              "  0.6146534085273743,\n",
              "  0.6161470413208008,\n",
              "  0.6181211471557617,\n",
              "  0.6166887879371643,\n",
              "  0.6170340776443481,\n",
              "  0.6049438714981079,\n",
              "  0.62000972032547,\n",
              "  0.6152805685997009,\n",
              "  0.6216568946838379,\n",
              "  0.6231831312179565,\n",
              "  0.6159924864768982,\n",
              "  0.6145025491714478,\n",
              "  0.618809700012207,\n",
              "  0.6142459511756897,\n",
              "  0.6137105226516724,\n",
              "  0.6208563446998596,\n",
              "  0.6078783869743347,\n",
              "  0.6187747120857239,\n",
              "  0.6170207858085632,\n",
              "  0.615312397480011,\n",
              "  0.6190029978752136,\n",
              "  0.6239094734191895,\n",
              "  0.613783061504364,\n",
              "  0.6151098012924194,\n",
              "  0.6180512309074402,\n",
              "  0.6200199127197266,\n",
              "  0.6166293025016785,\n",
              "  0.6202359795570374,\n",
              "  0.617387056350708,\n",
              "  0.6180517673492432,\n",
              "  0.6196349859237671,\n",
              "  0.6222084164619446,\n",
              "  0.62018221616745,\n",
              "  0.6137725114822388,\n",
              "  0.6197280883789062,\n",
              "  0.6103650331497192,\n",
              "  0.6128614544868469]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RN_Regresion.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YwxA_edWKPi",
        "outputId": "0d46e8e6-20d7-4732-f98a-9271e684274d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1569 - mae: 0.8949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.178137183189392, 0.9037420153617859]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Regresion Lineal Polinomial"
      ],
      "metadata": {
        "id": "_sM7ffhmXoo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformo el dataset en un dataset polinomial\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "\n",
        "X_train_poly=poly.fit_transform(X_train)\n",
        "X_test_poly=poly.fit_transform(X_test)\n",
        "X_val_poly=poly.fit_transform(X_val)\n",
        "\n",
        "X_train_poly.shape, X_test_poly.shape, X_val_poly.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7lrfFVgXvpF",
        "outputId": "c2cccc5b-f80b-4896-b89e-447bfb1ced39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((29894, 10), (9339, 10), (7474, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo la red neuronal con el dataset polinomial grado 2\n",
        "\n",
        "RN_Regresion_poly2=build_model_regresion(0.001,128,0.20,10)\n",
        "RN_Regresion_poly2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Fxe2-bmmZuwK",
        "outputId": "35f9e8a9-33eb-4fb3-cf54-240fd73bbe4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,049\u001b[0m (70.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,049</span> (70.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,049\u001b[0m (70.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,049</span> (70.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "History2=RN_Regresion_poly2.fit(X_train_poly,\n",
        "                         y_train,\n",
        "                         epochs=100,\n",
        "                         batch_size=512,\n",
        "                         validation_data=(X_val_poly,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sG0jfzIRZ_wG",
        "outputId": "250a33a1-0f7e-4fdb-e873-db73008892e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 1.4811 - mae: 0.6655 - val_loss: 8.9676 - val_mae: 0.6772\n",
            "Epoch 2/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.5872 - mae: 0.6623 - val_loss: 0.9680 - val_mae: 0.6196\n",
            "Epoch 3/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 1.6636 - mae: 0.6379 - val_loss: 0.9211 - val_mae: 0.6584\n",
            "Epoch 4/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 3.0695 - mae: 0.6739 - val_loss: 0.9724 - val_mae: 0.6236\n",
            "Epoch 5/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.8619 - mae: 0.6364 - val_loss: 11.1017 - val_mae: 0.7000\n",
            "Epoch 6/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.4307 - mae: 0.6552 - val_loss: 1.0892 - val_mae: 0.6302\n",
            "Epoch 7/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.7387 - mae: 0.6353 - val_loss: 5.7269 - val_mae: 0.6883\n",
            "Epoch 8/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.1608 - mae: 0.6671 - val_loss: 0.9203 - val_mae: 0.6226\n",
            "Epoch 9/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9283 - mae: 0.6245 - val_loss: 0.9383 - val_mae: 0.6150\n",
            "Epoch 10/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9662 - mae: 0.6228 - val_loss: 1.4173 - val_mae: 0.6238\n",
            "Epoch 11/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9377 - mae: 0.6258 - val_loss: 1.2247 - val_mae: 0.6207\n",
            "Epoch 12/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3590 - mae: 0.6270 - val_loss: 0.9077 - val_mae: 0.6042\n",
            "Epoch 13/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9586 - mae: 0.6107 - val_loss: 1.1247 - val_mae: 0.6181\n",
            "Epoch 14/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4664 - mae: 0.6410 - val_loss: 0.8797 - val_mae: 0.6156\n",
            "Epoch 15/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8608 - mae: 0.6243 - val_loss: 0.9101 - val_mae: 0.6365\n",
            "Epoch 16/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.1327 - mae: 0.6696 - val_loss: 0.8736 - val_mae: 0.6157\n",
            "Epoch 17/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9381 - mae: 0.6166 - val_loss: 0.9199 - val_mae: 0.6175\n",
            "Epoch 18/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2231 - mae: 0.6269 - val_loss: 1.0940 - val_mae: 0.6200\n",
            "Epoch 19/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9203 - mae: 0.6102 - val_loss: 1.2810 - val_mae: 0.6163\n",
            "Epoch 20/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0561 - mae: 0.6131 - val_loss: 0.8680 - val_mae: 0.6080\n",
            "Epoch 21/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.9910 - mae: 0.6197 - val_loss: 0.9083 - val_mae: 0.6122\n",
            "Epoch 22/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9268 - mae: 0.6175 - val_loss: 0.9982 - val_mae: 0.6158\n",
            "Epoch 23/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0632 - mae: 0.6211 - val_loss: 0.8876 - val_mae: 0.6054\n",
            "Epoch 24/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9304 - mae: 0.6180 - val_loss: 0.9882 - val_mae: 0.6133\n",
            "Epoch 25/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9844 - mae: 0.6179 - val_loss: 0.9120 - val_mae: 0.6242\n",
            "Epoch 26/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1255 - mae: 0.6156 - val_loss: 1.0055 - val_mae: 0.6192\n",
            "Epoch 27/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9398 - mae: 0.6229 - val_loss: 0.8946 - val_mae: 0.6187\n",
            "Epoch 28/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9131 - mae: 0.6110 - val_loss: 0.8759 - val_mae: 0.6169\n",
            "Epoch 29/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8966 - mae: 0.6208 - val_loss: 0.9823 - val_mae: 0.6254\n",
            "Epoch 30/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9992 - mae: 0.6164 - val_loss: 1.1357 - val_mae: 0.6177\n",
            "Epoch 31/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9574 - mae: 0.6173 - val_loss: 0.9403 - val_mae: 0.6141\n",
            "Epoch 32/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8994 - mae: 0.6163 - val_loss: 0.8747 - val_mae: 0.6126\n",
            "Epoch 33/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9343 - mae: 0.6154 - val_loss: 0.8795 - val_mae: 0.6200\n",
            "Epoch 34/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9556 - mae: 0.6235 - val_loss: 0.9519 - val_mae: 0.6229\n",
            "Epoch 35/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0047 - mae: 0.6255 - val_loss: 0.8763 - val_mae: 0.6151\n",
            "Epoch 36/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8729 - mae: 0.6100 - val_loss: 0.9829 - val_mae: 0.6202\n",
            "Epoch 37/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0306 - mae: 0.6241 - val_loss: 0.9311 - val_mae: 0.6167\n",
            "Epoch 38/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9021 - mae: 0.6164 - val_loss: 0.8981 - val_mae: 0.6199\n",
            "Epoch 39/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8878 - mae: 0.6118 - val_loss: 0.8667 - val_mae: 0.6147\n",
            "Epoch 40/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8982 - mae: 0.6138 - val_loss: 0.8940 - val_mae: 0.6164\n",
            "Epoch 41/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9496 - mae: 0.6143 - val_loss: 0.8695 - val_mae: 0.6175\n",
            "Epoch 42/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8750 - mae: 0.6159 - val_loss: 0.8687 - val_mae: 0.6225\n",
            "Epoch 43/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.9297 - mae: 0.6184 - val_loss: 0.8688 - val_mae: 0.6158\n",
            "Epoch 44/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.8950 - mae: 0.6194 - val_loss: 0.8970 - val_mae: 0.6168\n",
            "Epoch 45/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0190 - mae: 0.6236 - val_loss: 0.9205 - val_mae: 0.6207\n",
            "Epoch 46/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0209 - mae: 0.6171 - val_loss: 0.8678 - val_mae: 0.6116\n",
            "Epoch 47/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9523 - mae: 0.6128 - val_loss: 0.8750 - val_mae: 0.6209\n",
            "Epoch 48/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0333 - mae: 0.6153 - val_loss: 0.8726 - val_mae: 0.6202\n",
            "Epoch 49/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9117 - mae: 0.6158 - val_loss: 0.9658 - val_mae: 0.6237\n",
            "Epoch 50/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8935 - mae: 0.6171 - val_loss: 0.9167 - val_mae: 0.6201\n",
            "Epoch 51/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0983 - mae: 0.6121 - val_loss: 0.9413 - val_mae: 0.6266\n",
            "Epoch 52/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9584 - mae: 0.6239 - val_loss: 0.9040 - val_mae: 0.6148\n",
            "Epoch 53/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0500 - mae: 0.6109 - val_loss: 0.8750 - val_mae: 0.6168\n",
            "Epoch 54/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8733 - mae: 0.6125 - val_loss: 0.8681 - val_mae: 0.6181\n",
            "Epoch 55/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9542 - mae: 0.6226 - val_loss: 0.8792 - val_mae: 0.6228\n",
            "Epoch 56/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3137 - mae: 0.6275 - val_loss: 0.8681 - val_mae: 0.6137\n",
            "Epoch 57/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5162 - mae: 0.6114 - val_loss: 0.8702 - val_mae: 0.6167\n",
            "Epoch 58/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8998 - mae: 0.6189 - val_loss: 0.8737 - val_mae: 0.6199\n",
            "Epoch 59/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9329 - mae: 0.6229 - val_loss: 0.8708 - val_mae: 0.6151\n",
            "Epoch 60/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8871 - mae: 0.6129 - val_loss: 0.9061 - val_mae: 0.6189\n",
            "Epoch 61/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8888 - mae: 0.6187 - val_loss: 0.8779 - val_mae: 0.6164\n",
            "Epoch 62/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9342 - mae: 0.6172 - val_loss: 0.8715 - val_mae: 0.6148\n",
            "Epoch 63/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8949 - mae: 0.6172 - val_loss: 0.8713 - val_mae: 0.6176\n",
            "Epoch 64/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8992 - mae: 0.6182 - val_loss: 0.8849 - val_mae: 0.6135\n",
            "Epoch 65/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8716 - mae: 0.6095 - val_loss: 0.8701 - val_mae: 0.6169\n",
            "Epoch 66/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8742 - mae: 0.6120 - val_loss: 0.9184 - val_mae: 0.6200\n",
            "Epoch 67/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8951 - mae: 0.6116 - val_loss: 0.8701 - val_mae: 0.6201\n",
            "Epoch 68/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.9695 - mae: 0.6125 - val_loss: 0.8877 - val_mae: 0.6195\n",
            "Epoch 69/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8619 - mae: 0.6109 - val_loss: 0.8716 - val_mae: 0.6156\n",
            "Epoch 70/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8849 - mae: 0.6161 - val_loss: 0.8699 - val_mae: 0.6147\n",
            "Epoch 71/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8772 - mae: 0.6126 - val_loss: 0.9196 - val_mae: 0.6209\n",
            "Epoch 72/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8620 - mae: 0.6095 - val_loss: 0.8756 - val_mae: 0.6155\n",
            "Epoch 73/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9401 - mae: 0.6144 - val_loss: 0.9208 - val_mae: 0.6185\n",
            "Epoch 74/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9714 - mae: 0.6250 - val_loss: 0.8697 - val_mae: 0.6141\n",
            "Epoch 75/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8496 - mae: 0.6043 - val_loss: 0.8731 - val_mae: 0.6250\n",
            "Epoch 76/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9603 - mae: 0.6199 - val_loss: 0.8896 - val_mae: 0.6202\n",
            "Epoch 77/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8587 - mae: 0.6098 - val_loss: 0.8699 - val_mae: 0.6186\n",
            "Epoch 78/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8765 - mae: 0.6143 - val_loss: 0.8788 - val_mae: 0.6216\n",
            "Epoch 79/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8751 - mae: 0.6159 - val_loss: 0.8738 - val_mae: 0.6186\n",
            "Epoch 80/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9570 - mae: 0.6138 - val_loss: 0.8800 - val_mae: 0.6169\n",
            "Epoch 81/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8932 - mae: 0.6109 - val_loss: 0.8691 - val_mae: 0.6161\n",
            "Epoch 82/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9014 - mae: 0.6153 - val_loss: 0.8759 - val_mae: 0.6203\n",
            "Epoch 83/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8544 - mae: 0.6059 - val_loss: 0.8836 - val_mae: 0.6242\n",
            "Epoch 84/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9220 - mae: 0.6179 - val_loss: 0.8736 - val_mae: 0.6137\n",
            "Epoch 85/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8560 - mae: 0.6052 - val_loss: 0.9166 - val_mae: 0.6235\n",
            "Epoch 86/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8759 - mae: 0.6163 - val_loss: 0.8728 - val_mae: 0.6209\n",
            "Epoch 87/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8676 - mae: 0.6153 - val_loss: 0.9001 - val_mae: 0.6243\n",
            "Epoch 88/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8992 - mae: 0.6203 - val_loss: 0.8702 - val_mae: 0.6164\n",
            "Epoch 89/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8741 - mae: 0.6154 - val_loss: 0.8807 - val_mae: 0.6150\n",
            "Epoch 90/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.8384 - mae: 0.6031 - val_loss: 0.9827 - val_mae: 0.6201\n",
            "Epoch 91/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9014 - mae: 0.6199 - val_loss: 0.8697 - val_mae: 0.6113\n",
            "Epoch 92/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9608 - mae: 0.6144 - val_loss: 0.8803 - val_mae: 0.6209\n",
            "Epoch 93/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8943 - mae: 0.6198 - val_loss: 0.8714 - val_mae: 0.6219\n",
            "Epoch 94/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8745 - mae: 0.6158 - val_loss: 0.8759 - val_mae: 0.6182\n",
            "Epoch 95/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9142 - mae: 0.6070 - val_loss: 0.8705 - val_mae: 0.6188\n",
            "Epoch 96/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9569 - mae: 0.6166 - val_loss: 0.9280 - val_mae: 0.6223\n",
            "Epoch 97/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8898 - mae: 0.6158 - val_loss: 0.8849 - val_mae: 0.6200\n",
            "Epoch 98/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8886 - mae: 0.6139 - val_loss: 0.8823 - val_mae: 0.6130\n",
            "Epoch 99/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8979 - mae: 0.6177 - val_loss: 0.8896 - val_mae: 0.6184\n",
            "Epoch 100/100\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8627 - mae: 0.6073 - val_loss: 0.8912 - val_mae: 0.6169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RN_Regresion_poly2.evaluate(X_test_poly,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDW4JJ95c_9l",
        "outputId": "935850fa-9cb2-452b-ddb7-4cc0d0e3e8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3019 - mae: 0.9152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2680177688598633, 0.9214913249015808]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Regresion Polinomial Grado 3\n"
      ],
      "metadata": {
        "id": "Mgwhb-4AdQLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "\n",
        "X_train_poly3=poly.fit_transform(X_train)\n",
        "X_test_poly3=poly.fit_transform(X_test)\n",
        "X_val_poly3=poly.fit_transform(X_val)\n",
        "\n",
        "X_train_poly3.shape, X_test_poly3.shape, X_val_poly3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tkhWaOfdXp7",
        "outputId": "7e381e19-f0e7-4b4e-e5c8-16e3bd441588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((29894, 20), (9339, 20), (7474, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RN_Regresion_poly3=build_model_regresion(0.001,16,0.20,20)\n",
        "RN_Regresion_poly3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "iYLRItLBdo4w",
        "outputId": "d7ecb629-4658-4d16-c97a-36afbb4f5171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m625\u001b[0m (2.44 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">625</span> (2.44 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m625\u001b[0m (2.44 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">625</span> (2.44 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "History3=RN_Regresion_poly3.fit(X_train_poly3,\n",
        "                         y_train,\n",
        "                         epochs=100,\n",
        "                         batch_size=32,\n",
        "                         validation_data=(X_val_poly3,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cq5vr4oOdvU6",
        "outputId": "5ad795f9-a348-464e-8f08-42cec464b36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 576.0444 - mae: 1.0998 - val_loss: 6254.7710 - val_mae: 1.8869\n",
            "Epoch 2/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 932.2343 - mae: 1.1879 - val_loss: 2814.2839 - val_mae: 1.3587\n",
            "Epoch 3/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 644.3853 - mae: 1.0361 - val_loss: 115.8536 - val_mae: 0.7939\n",
            "Epoch 4/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1004.6022 - mae: 1.1179 - val_loss: 650.7427 - val_mae: 0.9667\n",
            "Epoch 5/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 705.0059 - mae: 0.9200 - val_loss: 278.5200 - val_mae: 0.9028\n",
            "Epoch 6/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1700.9478 - mae: 1.1433 - val_loss: 694.9827 - val_mae: 1.1148\n",
            "Epoch 7/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 790.3846 - mae: 1.0228 - val_loss: 286.0191 - val_mae: 0.9375\n",
            "Epoch 8/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 877.9879 - mae: 0.9954 - val_loss: 54.2489 - val_mae: 0.7732\n",
            "Epoch 9/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1211.4845 - mae: 1.0845 - val_loss: 152.1177 - val_mae: 0.8137\n",
            "Epoch 10/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5894.6445 - mae: 1.5014 - val_loss: 138.1902 - val_mae: 0.8168\n",
            "Epoch 11/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1777.3241 - mae: 1.2437 - val_loss: 1199.1621 - val_mae: 1.0649\n",
            "Epoch 12/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 344.4207 - mae: 0.7476 - val_loss: 23.8169 - val_mae: 0.7050\n",
            "Epoch 13/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 29.9068 - mae: 0.6963 - val_loss: 39.6364 - val_mae: 0.7224\n",
            "Epoch 14/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 29.7679 - mae: 0.6855 - val_loss: 26.0284 - val_mae: 0.6857\n",
            "Epoch 15/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 113.3151 - mae: 0.7214 - val_loss: 84.6090 - val_mae: 0.7548\n",
            "Epoch 16/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 677.5040 - mae: 0.8951 - val_loss: 7.0950 - val_mae: 0.6627\n",
            "Epoch 17/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 222.9783 - mae: 0.7657 - val_loss: 177.4771 - val_mae: 0.7663\n",
            "Epoch 18/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 56.3355 - mae: 0.6669 - val_loss: 7.4788 - val_mae: 0.6609\n",
            "Epoch 19/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15.6848 - mae: 0.6566 - val_loss: 14.6649 - val_mae: 0.6714\n",
            "Epoch 20/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.8980 - mae: 0.6306 - val_loss: 1.9843 - val_mae: 0.6565\n",
            "Epoch 21/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 44.2007 - mae: 0.6796 - val_loss: 18.7504 - val_mae: 0.6800\n",
            "Epoch 22/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 76.7914 - mae: 0.6695 - val_loss: 12.8795 - val_mae: 0.6600\n",
            "Epoch 23/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1585.7057 - mae: 1.0513 - val_loss: 1.3591 - val_mae: 0.6327\n",
            "Epoch 24/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 25.3835 - mae: 0.6605 - val_loss: 14.1299 - val_mae: 0.6720\n",
            "Epoch 25/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 36.3812 - mae: 0.6783 - val_loss: 1.2255 - val_mae: 0.6303\n",
            "Epoch 26/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.1842 - mae: 0.6367 - val_loss: 0.9804 - val_mae: 0.6207\n",
            "Epoch 27/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 26.8099 - mae: 0.6695 - val_loss: 0.9224 - val_mae: 0.6275\n",
            "Epoch 28/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 62.1573 - mae: 0.6681 - val_loss: 0.9803 - val_mae: 0.6344\n",
            "Epoch 29/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 29.3329 - mae: 0.6537 - val_loss: 1.3049 - val_mae: 0.6379\n",
            "Epoch 30/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 817.5468 - mae: 1.0075 - val_loss: 0.9035 - val_mae: 0.6204\n",
            "Epoch 31/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 449.3145 - mae: 0.7462 - val_loss: 0.9365 - val_mae: 0.6305\n",
            "Epoch 32/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 164.7643 - mae: 0.7841 - val_loss: 0.9296 - val_mae: 0.6292\n",
            "Epoch 33/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.8009 - mae: 0.6299 - val_loss: 0.8951 - val_mae: 0.6369\n",
            "Epoch 34/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 23.1822 - mae: 0.6404 - val_loss: 0.8942 - val_mae: 0.6212\n",
            "Epoch 35/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 120.6965 - mae: 0.6566 - val_loss: 1.6438 - val_mae: 0.6433\n",
            "Epoch 36/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13.8181 - mae: 0.6391 - val_loss: 0.8809 - val_mae: 0.6231\n",
            "Epoch 37/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.2900 - mae: 0.6332 - val_loss: 0.8963 - val_mae: 0.6205\n",
            "Epoch 38/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.5459 - mae: 0.6412 - val_loss: 0.9372 - val_mae: 0.6246\n",
            "Epoch 39/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.0412 - mae: 0.6290 - val_loss: 0.9284 - val_mae: 0.6156\n",
            "Epoch 40/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 76.8484 - mae: 0.7205 - val_loss: 0.9344 - val_mae: 0.6233\n",
            "Epoch 41/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.4662 - mae: 0.6294 - val_loss: 0.9884 - val_mae: 0.6230\n",
            "Epoch 42/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14.0861 - mae: 0.6370 - val_loss: 0.9751 - val_mae: 0.6230\n",
            "Epoch 43/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.0273 - mae: 0.6269 - val_loss: 1.0083 - val_mae: 0.6268\n",
            "Epoch 44/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.1898 - mae: 0.6150 - val_loss: 0.9403 - val_mae: 0.6262\n",
            "Epoch 45/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 25.2617 - mae: 0.6598 - val_loss: 0.9689 - val_mae: 0.6279\n",
            "Epoch 46/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 27.0854 - mae: 0.6468 - val_loss: 0.8809 - val_mae: 0.6257\n",
            "Epoch 47/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13.0206 - mae: 0.6345 - val_loss: 0.8755 - val_mae: 0.6185\n",
            "Epoch 48/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 33.9970 - mae: 0.6705 - val_loss: 0.8895 - val_mae: 0.6335\n",
            "Epoch 49/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.9745 - mae: 0.6249 - val_loss: 0.9802 - val_mae: 0.6468\n",
            "Epoch 50/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 32.4394 - mae: 0.6647 - val_loss: 0.9141 - val_mae: 0.6201\n",
            "Epoch 51/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.6584 - mae: 0.6276 - val_loss: 0.9546 - val_mae: 0.6273\n",
            "Epoch 52/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 14.0588 - mae: 0.6441 - val_loss: 0.8864 - val_mae: 0.6165\n",
            "Epoch 53/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12.1892 - mae: 0.6264 - val_loss: 1.0147 - val_mae: 0.6318\n",
            "Epoch 54/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.3954 - mae: 0.6196 - val_loss: 0.8859 - val_mae: 0.6042\n",
            "Epoch 55/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.8168 - mae: 0.6360 - val_loss: 0.8751 - val_mae: 0.6128\n",
            "Epoch 56/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 50.2385 - mae: 0.6792 - val_loss: 0.8906 - val_mae: 0.6185\n",
            "Epoch 57/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9073 - mae: 0.6208 - val_loss: 0.8974 - val_mae: 0.6221\n",
            "Epoch 58/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.0553 - mae: 0.6191 - val_loss: 0.8821 - val_mae: 0.6239\n",
            "Epoch 59/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9592 - mae: 0.6172 - val_loss: 0.8912 - val_mae: 0.6178\n",
            "Epoch 60/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3197 - mae: 0.6202 - val_loss: 0.8734 - val_mae: 0.6178\n",
            "Epoch 61/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.9111 - mae: 0.6493 - val_loss: 0.8930 - val_mae: 0.6254\n",
            "Epoch 62/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9422 - mae: 0.6143 - val_loss: 0.9044 - val_mae: 0.6299\n",
            "Epoch 63/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.5121 - mae: 0.6197 - val_loss: 0.8721 - val_mae: 0.6192\n",
            "Epoch 64/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 24.3295 - mae: 0.6737 - val_loss: 0.8787 - val_mae: 0.6262\n",
            "Epoch 65/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.4817 - mae: 0.6208 - val_loss: 0.8706 - val_mae: 0.6247\n",
            "Epoch 66/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.3488 - mae: 0.6366 - val_loss: 0.8907 - val_mae: 0.6288\n",
            "Epoch 67/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.9018 - mae: 0.6214 - val_loss: 0.8873 - val_mae: 0.6313\n",
            "Epoch 68/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9399 - mae: 0.6228 - val_loss: 0.8820 - val_mae: 0.6295\n",
            "Epoch 69/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9343 - mae: 0.6207 - val_loss: 0.8979 - val_mae: 0.6260\n",
            "Epoch 70/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.3165 - mae: 0.6140 - val_loss: 0.8699 - val_mae: 0.6213\n",
            "Epoch 71/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.8934 - mae: 0.6187 - val_loss: 0.8783 - val_mae: 0.6280\n",
            "Epoch 72/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9460 - mae: 0.6210 - val_loss: 0.8706 - val_mae: 0.6262\n",
            "Epoch 73/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8989 - mae: 0.6164 - val_loss: 0.8827 - val_mae: 0.6256\n",
            "Epoch 74/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9281 - mae: 0.6293 - val_loss: 0.8923 - val_mae: 0.6350\n",
            "Epoch 75/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.1339 - mae: 0.6232 - val_loss: 0.8790 - val_mae: 0.6240\n",
            "Epoch 76/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.8950 - mae: 0.6219 - val_loss: 0.8829 - val_mae: 0.6267\n",
            "Epoch 77/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8851 - mae: 0.6218 - val_loss: 0.8748 - val_mae: 0.6247\n",
            "Epoch 78/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8983 - mae: 0.6165 - val_loss: 0.8982 - val_mae: 0.6293\n",
            "Epoch 79/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8760 - mae: 0.6197 - val_loss: 0.9057 - val_mae: 0.6276\n",
            "Epoch 80/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8743 - mae: 0.6146 - val_loss: 0.9195 - val_mae: 0.6363\n",
            "Epoch 81/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.8999 - mae: 0.6202 - val_loss: 0.9795 - val_mae: 0.6232\n",
            "Epoch 82/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8711 - mae: 0.6122 - val_loss: 0.9235 - val_mae: 0.6296\n",
            "Epoch 83/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8928 - mae: 0.6190 - val_loss: 0.9693 - val_mae: 0.6202\n",
            "Epoch 84/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8721 - mae: 0.6122 - val_loss: 0.9774 - val_mae: 0.6350\n",
            "Epoch 85/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8735 - mae: 0.6181 - val_loss: 0.9877 - val_mae: 0.6230\n",
            "Epoch 86/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.9006 - mae: 0.6171 - val_loss: 0.9467 - val_mae: 0.6228\n",
            "Epoch 87/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8692 - mae: 0.6134 - val_loss: 0.9206 - val_mae: 0.6243\n",
            "Epoch 88/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8815 - mae: 0.6144 - val_loss: 0.9505 - val_mae: 0.6267\n",
            "Epoch 89/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.8844 - mae: 0.6159 - val_loss: 0.9559 - val_mae: 0.6293\n",
            "Epoch 90/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8808 - mae: 0.6169 - val_loss: 0.9623 - val_mae: 0.6299\n",
            "Epoch 91/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8747 - mae: 0.6138 - val_loss: 0.9335 - val_mae: 0.6212\n",
            "Epoch 92/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.9006 - mae: 0.6221 - val_loss: 1.0037 - val_mae: 0.6218\n",
            "Epoch 93/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8862 - mae: 0.6152 - val_loss: 0.9384 - val_mae: 0.6331\n",
            "Epoch 94/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8944 - mae: 0.6195 - val_loss: 0.9656 - val_mae: 0.6221\n",
            "Epoch 95/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8997 - mae: 0.6221 - val_loss: 1.2355 - val_mae: 0.6335\n",
            "Epoch 96/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.9676 - mae: 0.6187 - val_loss: 1.0479 - val_mae: 0.6208\n",
            "Epoch 97/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8437 - mae: 0.6076 - val_loss: 1.0092 - val_mae: 0.6362\n",
            "Epoch 98/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8705 - mae: 0.6152 - val_loss: 1.0386 - val_mae: 0.6276\n",
            "Epoch 99/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.8414 - mae: 0.6093 - val_loss: 1.0908 - val_mae: 0.6330\n",
            "Epoch 100/100\n",
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8752 - mae: 0.6138 - val_loss: 1.1160 - val_mae: 0.6386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RN_Regresion_poly3.evaluate(X_test_poly3,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRRzPKnzfxG7",
        "outputId": "68c7901d-28b8-4a5e-bf0b-96deca6828e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14.0884 - mae: 0.9707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.8587212562561035, 0.9285630583763123]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "en este Reto se han usado los hiperparametros de learning rate , el numero de neuronas por cada capa el porcentaje de dropout y el numero de parametros que recibe la red neruonal , la funcion build model regresion es la encaegada de recibir estos parametros y construir la red neuronal\n",
        "\n",
        "1. en el caso de la red neuronal se escogieron las tres variables mas correlacionadas con la variable objetivo\n",
        "2. se pudo observar que la red neuronal simple con las tres variables sobeajusto soloamente estandarizadas el sobreajuste empezo cuando por encima de las 32 neuronas en cada capa por debajo de 32 neuronas se mantuvo estable el valor del \"MAE\"\n",
        "3. se desarrollo un polinomio de grado 2 la red empezo a sobreajustar cuando se ponian mas de 32 neuronas\n",
        "4. en el polinomio grado 3 sobreajusto desde las 16 neuronas y no es un buen modelo con las varibles que se tiene para la regresion lineal\n",
        "5. se necesitan mas variables para evitar el sobreajuste y seguir modificando los hiperparametros para ver cual es la mejor opcion para la regresion"
      ],
      "metadata": {
        "id": "VpGsCI8slU5M"
      }
    }
  ]
}